{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fdf3e42",
   "metadata": {},
   "source": [
    "HTMLHeaderTextSplitter is a \"stucture-aware\" chunker that splits text at the HTML element level and adds metadata for each header 'relevant ' to any given chunk. it can return chunks element or combine elments with the same metadata, with the objectives if (a) kepping related text grouped (more or less) semantically and (b) preserving context-rich information encoded in document structures . it can be used with other text splitters as part of a chunking pipline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e646c6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'This is an H1 Header'}, page_content='This is an H1 Header'),\n",
       " Document(metadata={'Header 1': 'This is an H1 Header', 'Header 2': 'This is an H2 Header'}, page_content='This is an H2 Header'),\n",
       " Document(metadata={'Header 1': 'This is an H1 Header', 'Header 2': 'This is an H2 Header', 'Header 3': 'This is an H3 Header'}, page_content='This is an H3 Header'),\n",
       " Document(metadata={'Header 1': 'This is an H1 Header', 'Header 2': 'This is an H2 Header', 'Header 3': 'This is an H3 Header'}, page_content='This is an H4 Header  \\nThis is an H5 Header  \\nThis is an H6 Header  \\nThis is a paragraph of text. It demonstrates how paragraphs are displayed in HTML.\\n        You can write as much text as needed here. HTML will wrap the text automatically unless\\n        styled otherwise using CSS.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string=\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <title>Sample HTML Document</title>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "    <h1>This is an H1 Header</h1>\n",
    "    <h2>This is an H2 Header</h2>\n",
    "    <h3>This is an H3 Header</h3>\n",
    "    <h4>This is an H4 Header</h4>\n",
    "    <h5>This is an H5 Header</h5>\n",
    "    <h6>This is an H6 Header</h6>\n",
    "\n",
    "    <p>\n",
    "        This is a paragraph of text. It demonstrates how paragraphs are displayed in HTML.\n",
    "        You can write as much text as needed here. HTML will wrap the text automatically unless\n",
    "        styled otherwise using CSS.\n",
    "    </p>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "\"\"\"\n",
    "header_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=header_to_split_on)\n",
    "html_header_splits=html_splitter.split_text(html_string)\n",
    "html_header_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52557451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='start desktop header /end desktop header /end mobile-header  \\nSkip to main content  \\n/from April 7 at 1:00 AM to May 29 at 21:40 /from May 2 at 1:00 AM to May 5 at 9:45 AM  \\nWe gratefully acknowledge support from the Simons Foundation, , and all contributors.  \\nmember institutions  \\nDonate  \\narXiv:1706.03762  \\n>  \\ncs  \\n>  \\n|  \\nHelp  \\nAdvanced Search  \\nAll fields  \\nTitle  \\nAuthor  \\nAbstract  \\nComments  \\nJournal reference  \\nACM classification  \\nMSC classification  \\nReport number  \\narXiv identifier  \\nDOI  \\nORCID  \\narXiv author ID  \\nHelp pages  \\nFull text  \\nSearch  \\nopen search  \\nGO  \\nopen navigation menu'),\n",
       " Document(metadata={'Header 2': 'quick links'}, page_content='quick links'),\n",
       " Document(metadata={}, page_content='Login  \\nHelp Pages  \\nAbout  \\nrdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n         xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\\n         xmlns:trackback=\"http://madskills.com/public/xml/rss/module/trackback/\">\\n    <rdf:Description\\n        rdf:about=\"/abs/1706.03762\"\\n        dc:identifier=\"/abs/1706.03762\"\\n        dc:title=\"Attention Is All You Need\"\\n        trackback:ping=\"/trackback/1706.03762\" />\\n    </rdf:RDF>  \\nend leftcolumn end extra-services LABS AREA END LABS AREA'),\n",
       " Document(metadata={'Header 1': 'Computer Science > Computation and Language'}, page_content='Computer Science > Computation and Language'),\n",
       " Document(metadata={}, page_content='(cs)  \\narXiv:1706.03762  \\nCONTEXT  \\n[Submitted on 12 Jun 2017 ( ), last revised 2 Aug 2023 (this version, v7)]  \\nv1'),\n",
       " Document(metadata={'Header 1': 'Attention Is All You Need'}, page_content='Attention Is All You Need'),\n",
       " Document(metadata={}, page_content='Title:  \\n, , , , , , ,  \\nAuthors:  \\nAshish Vaswani  \\nNoam Shazeer  \\nNiki Parmar  \\nJakob Uszkoreit  \\nLlion Jones  \\nAidan N. Gomez  \\nLukasz Kaiser  \\nIllia Polosukhin  \\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors  \\nView PDF  \\nHTML (experimental)  \\nThe dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.  \\nAbstract:  \\nComments:  \\n15 pages, 5 figures  \\nSubjects:  \\n; Machine Learning (cs.LG)  \\nComputation and Language (cs.CL)  \\nCite as:  \\n[cs.CL]  \\narXiv:1706.03762  \\n(or for this version)  \\n[cs.CL]  \\narXiv:1706.03762v7  \\nhttps://doi.org/10.48550/arXiv.1706.03762  \\ntooltip description  \\nFocus to learn more  \\narXiv-issued DOI via DataCite  \\nFrom: Llion Jones [ ] Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB) Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB) Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB) Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB) Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB) Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB) Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)'),\n",
       " Document(metadata={'Header 2': 'Submission history'}, page_content='Submission history'),\n",
       " Document(metadata={}, page_content='view email  \\n[v1]  \\n[v2]  \\n[v3]  \\n[v4]  \\n[v5]  \\n[v6]  \\n[v7]  \\nend full-text  \\nFull-text links:'),\n",
       " Document(metadata={'Header 2': 'Access Paper:'}, page_content='Access Paper:'),\n",
       " Document(metadata={}, page_content='View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors  \\nView PDF  \\nHTML (experimental)  \\nTeX Source  \\nOther Formats  \\nview license  \\nCurrent browse context:  \\ncs.CL  \\n<\\xa0prev  \\n|  \\nnext\\xa0>  \\nnew  \\n|  \\nrecent  \\n|  \\n2017-06  \\nChange to browse by:  \\ncs  \\ncs.LG'),\n",
       " Document(metadata={'Header 3': 'References & Citations'}, page_content='References & Citations'),\n",
       " Document(metadata={'Header 3': 'References & Citations'}, page_content='NASA ADS  \\nGoogle Scholar  \\nSemantic Scholar  \\n( )  \\n123 blog links  \\nwhat is this?'),\n",
       " Document(metadata={'Header 3': '- CS Bibliography'}, page_content='- CS Bibliography'),\n",
       " Document(metadata={'Header 3': '- CS Bibliography'}, page_content='DBLP  \\n|  \\nlisting  \\nbibtex  \\nAshish Vaswani  \\nNoam Shazeer  \\nNiki Parmar  \\nJakob Uszkoreit  \\nLlion Jones  \\n…  \\na  \\nexport BibTeX citation  \\nLoading...'),\n",
       " Document(metadata={'Header 2': 'BibTeX formatted citation'}, page_content='BibTeX formatted citation'),\n",
       " Document(metadata={'Header 2': 'BibTeX formatted citation'}, page_content='×  \\nloading...  \\nData provided by:'),\n",
       " Document(metadata={'Header 2': 'BibTeX formatted citation', 'Header 3': 'Bookmark'}, page_content='Bookmark'),\n",
       " Document(metadata={}, page_content='Bibliographic Tools'),\n",
       " Document(metadata={'Header 1': 'Bibliographic and Citation Tools'}, page_content='Bibliographic and Citation Tools'),\n",
       " Document(metadata={}, page_content='Bibliographic Explorer Toggle  \\nBibliographic Explorer  \\n( )  \\nWhat is the Explorer?  \\nConnected Papers Toggle  \\nConnected Papers  \\n( )  \\nWhat is Connected Papers?  \\nLitmaps Toggle  \\nLitmaps  \\n( )  \\nWhat is Litmaps?  \\nscite.ai Toggle  \\nscite Smart Citations  \\n( )  \\nWhat are Smart Citations?  \\nCode, Data, Media'),\n",
       " Document(metadata={'Header 1': 'Code, Data and Media Associated with this Article'}, page_content='Code, Data and Media Associated with this Article'),\n",
       " Document(metadata={}, page_content='alphaXiv Toggle  \\nalphaXiv  \\n( )  \\nWhat is alphaXiv?  \\nLinks to Code Toggle  \\nCatalyzeX Code Finder for Papers  \\n( )  \\nWhat is CatalyzeX?  \\nDagsHub Toggle  \\nDagsHub  \\n( )  \\nWhat is DagsHub?  \\nGotitPub Toggle  \\nGotit.pub  \\n( )  \\nWhat is GotitPub?  \\nHuggingface Toggle  \\nHugging Face  \\n( )  \\nWhat is Huggingface?  \\nLinks to Code Toggle  \\nPapers with Code  \\n( )  \\nWhat is Papers with Code?  \\nScienceCast Toggle  \\nScienceCast  \\n( )  \\nWhat is ScienceCast?  \\nDemos'),\n",
       " Document(metadata={'Header 1': 'Demos'}, page_content='Demos'),\n",
       " Document(metadata={}, page_content='Replicate Toggle  \\nReplicate  \\n( )  \\nWhat is Replicate?  \\nSpaces Toggle  \\nHugging Face Spaces  \\n( )  \\nWhat is Spaces?  \\nSpaces Toggle  \\nTXYZ.AI  \\n( )  \\nWhat is TXYZ.AI?  \\nRelated Papers'),\n",
       " Document(metadata={'Header 1': 'Recommenders and Search Tools'}, page_content='Recommenders and Search Tools'),\n",
       " Document(metadata={}, page_content='Link to Influence Flower  \\nInfluence Flower  \\n( )  \\nWhat are Influence Flowers?  \\nCore recommender toggle  \\nCORE Recommender  \\n( )  \\nWhat is CORE?  \\nAuthor  \\nVenue  \\nInstitution  \\nTopic  \\nAbout arXivLabs'),\n",
       " Document(metadata={'Header 1': 'arXivLabs: experimental projects with community collaborators'}, page_content='arXivLabs: experimental projects with community collaborators'),\n",
       " Document(metadata={}, page_content=\"arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.  \\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.  \\nHave an idea for a project that will add value for arXiv's community? .  \\nLearn more about arXivLabs  \\n| ( )  \\nWhich authors of this paper are endorsers?  \\nDisable MathJax  \\nWhat is MathJax?  \\nmathjaxToggle();  \\nMacro-Column 1 End Macro-Column 1 Macro-Column 2 end MetaColumn 2 End Macro-Column 2  \\nAbout  \\nHelp  \\ncontact arXiv  \\nClick here to contact arXiv  \\nContact  \\nsubscribe to arXiv mailings  \\nClick here to subscribe  \\nSubscribe  \\nCopyright  \\nPrivacy Policy  \\nWeb Accessibility Assistance  \\nGet status notifications via or  \\narXiv Operational Status  \\nemail  \\nslack\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split html from a url as well\n",
    "\n",
    "url = \"https://arxiv.org/abs/1706.03762\"\n",
    "header_to_split_on=[\n",
    "    (\"h1\",\"Header 1\"),\n",
    "    (\"h2\",\"Header 2\"),\n",
    "    (\"h3\",\"Header 3\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=header_to_split_on)\n",
    "html_header_splits=html_splitter.split_text_from_url(url)\n",
    "html_header_splits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6d348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c149fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c799bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
